{
 "metadata": {
  "name": "PSM.ipynb",
  "signature": "sha256:daf845121b68fedc6c20fe71f5f45290441e727ef67b53809f4a1ba57a794f9d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Created 7/9/2014 by KO\n",
      "</br>\n",
      "Implements propensity-score matching and eventually will implement balance diagnostics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import math\n",
      "import numpy as np\n",
      "import scipy\n",
      "from scipy.stats import binom, hypergeom\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implement one-to-one matching, caliper without replacement.  Variants of the method are examined in the following paper.  This is something to explore further.\n",
      "</br>\n",
      "Austin, P. C. (2014), A comparison of 12 algorithms for matching on the propensity score. Statist. Med., 33: 1057\u20131069. doi: 10.1002/sim.6004"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Match(groups, propensity, caliper = 0.05):\n",
      "    ''' \n",
      "    Inputs:\n",
      "    groups = Treatment assignments.  Must be 2 groups\n",
      "    propensity = Propensity scores for each observation. Propensity and groups should be in the same order (matching indices)\n",
      "    caliper = Maximum difference in matched propensity scores. For now, this is a caliper on the raw\n",
      "            propensity; Austin reccommends using a caliper on the logit propensity.\n",
      "    \n",
      "    Output:\n",
      "    A series containing the individuals in the control group matched to the treatment group.\n",
      "    Note that with caliper matching, not every treated individual may have a match.\n",
      "    '''\n",
      "\n",
      "    # Check inputs\n",
      "    if any(propensity <=0) or any(propensity >=1):\n",
      "        raise ValueError('Propensity scores must be between 0 and 1')\n",
      "    elif not(0<=caliper<1):\n",
      "        raise ValueError('Caliper must be between 0 and 1')\n",
      "    elif len(groups)!= len(propensity):\n",
      "        raise ValueError('groups and propensity scores must be same dimension')\n",
      "    elif len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups')\n",
      "        \n",
      "        \n",
      "    # Code groups as 0 and 1\n",
      "    groups = groups == groups.unique()[0]\n",
      "    N = len(groups)\n",
      "    N1 = groups.sum(); N2 = N-N1\n",
      "    g1, g2 = propensity[groups == 1], (propensity[groups == 0])\n",
      "    # Check if treatment groups got flipped - treatment (coded 1) should be the smaller\n",
      "    if N1 > N2:\n",
      "       N1, N2, g1, g2 = N2, N1, g2, g1 \n",
      "        \n",
      "        \n",
      "    # Randomly permute the smaller group to get order for matching\n",
      "    morder = np.random.permutation(N1)\n",
      "    matches = pd.Series(np.empty(N1))\n",
      "    matches[:] = np.NAN\n",
      "    \n",
      "    for m in morder:\n",
      "        dist = abs(g1[m] - g2)\n",
      "        if dist.min() <= caliper:\n",
      "            matches[m] = dist.argmin()\n",
      "            g2 = g2.drop(matches[m])\n",
      "    return (matches)\n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Goal:</b> find the average treatment effect in the treatment group (ATT) on RE78.\n",
      "\n",
      "<b>Import the data:</b> controls and treated from Lalonde/Dehejia papers.  Here's what the site says about the data:\n",
      "\n",
      "The variables from left to right are: treatment indicator (1 if treated, 0 if not treated), age, education, Black (1 if black, 0 otherwise), Hispanic (1 if Hispanic, 0 otherwise), married (1 if married, 0 otherwise), nodegree (1 if no degree, 0 otherwise), RE74 (earnings in 1974), RE75 (earnings in 1975), and RE78 (earnings in 1978).\n",
      "\n",
      "http://users.nber.org/%7Erdehejia/nswdata2.html\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = ['Treated', 'Age', 'Education', 'Black', 'Hispanic', 'Married',\n",
      "         'Nodegree', 'RE74', 'RE75', 'RE78']\n",
      "treated = pd.read_table('/Users/Kellie/Documents/ModelMatch/Data/nswre74_treated.txt', sep = '\\s+',\n",
      "                        header = None, names = names)\n",
      "control = pd.read_table('/Users/Kellie/Documents/ModelMatch/Data/nswre74_control.txt', sep='\\s+', \n",
      "                        header = None, names = names)\n",
      "data = pd.concat([treated, control])\n",
      "print data.head()\n",
      "\n",
      "# Verify some characteristics match the Dehejia & Wahba paper, see table 1\n",
      "print mean(data.Age[data.Treated == 0]), mean(data.Age[data.Treated == 1])\n",
      "print mean(data.Education[data.Treated == 0]), mean(data.Education[data.Treated == 1])\n",
      "print mean(data.Black[data.Treated == 0]), mean(data.Black[data.Treated == 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   Treated  Age  Education  Black  Hispanic  Married  Nodegree  RE74  RE75  \\\n",
        "0        1   37         11      1         0        1         1     0     0   \n",
        "1        1   22          9      0         1        0         1     0     0   \n",
        "2        1   30         12      1         0        0         0     0     0   \n",
        "3        1   27         11      1         0        0         1     0     0   \n",
        "4        1   33          8      1         0        0         1     0     0   \n",
        "\n",
        "         RE78  \n",
        "0   9930.0460  \n",
        "1   3595.8940  \n",
        "2  24909.4500  \n",
        "3   7506.1460  \n",
        "4    289.7899  \n",
        "25.0538461538 25.8162162162\n",
        "10.0884615385 10.3459459459\n",
        "0.826923076923 0.843243243243\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Compute propensity scores</b> to start.  Then we need to separate the treated and controls again (preserve original indexing) in order to match them.\n",
      "\n",
      "\n",
      "We need to compute some additional variables that Dehejia and Wahba use in the model for propensity scores.  Refer to the appendix of their paper to see how they decided to include these variables.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['Age2'] = data['Age']**2\n",
      "data['Age3'] = data['Age']**3\n",
      "data['School2'] = data['Education']**2\n",
      "data['U74'] = (data['RE74']==0).astype('int')\n",
      "data['U75'] = (data['RE75']==0).astype('int')\n",
      "data['SchoolRE74'] = data['Education']*data['RE74']\n",
      "\n",
      "predictors = [col for col in data.columns if col not in ['Treated', 'RE78']]\n",
      "propensity = LogisticRegression()\n",
      "propensity = propensity.fit(data.loc[:,predictors], data.Treated)\n",
      "pscore = propensity.predict_proba(data[predictors])[:,1] # The predicted propensities by the model\n",
      "print pscore[:5]\n",
      "\n",
      "data['Propensity'] = pscore\n",
      "#pscore = pd.Series(data = pscore, index = data.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.38550967  0.2645061   0.50870121  0.37736731  0.39359452]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stuff = Match(data.Treated, data.Propensity, caliper = 0)\n",
      "g1, g2 = data.Propensity[data.Treated==1], data.Propensity[data.Treated==0]\n",
      "\n",
      "# test ValueError\n",
      "#badtreat = data.Treated + data.Hispanic\n",
      "#Match(badtreat, pscore)\n",
      "\n",
      "stuff[:5] # The first 5 matched pairs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "0   NaN\n",
        "1   NaN\n",
        "2    75\n",
        "3   NaN\n",
        "4   NaN\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Here's the result:</b> if we put the propensity scores of the treatment and matched controls side-by-side, we see that they're matched pretty well.\n",
      "<br>\n",
      "Furthermore, with caliper set to 0, the mean propensity for the control group matches Dehejia and Wahba (see table 2, first row)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip(g1, g2[stuff])\n",
      "mean(g1), mean(g2[stuff]), mean(pscore) #"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "(0.44082326632578323, 0.3718752193182448, 0.41499457600702122)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}