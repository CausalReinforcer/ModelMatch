{
 "metadata": {
  "name": "PSM.ipynb",
  "signature": "sha256:daf845121b68fedc6c20fe71f5f45290441e727ef67b53809f4a1ba57a794f9d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Last edited 22 July, 2014 by KO\n",
      "</br>\n",
      "Implements propensity-score matching and eventually will implement balance diagnostics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import math\n",
      "import numpy as np\n",
      "import scipy\n",
      "from scipy.stats import binom, hypergeom\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from ModelMatch import binByQuantiles\n",
      "import statsmodels.api as sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implement one-to-one matching, caliper without replacement.  Variants of the method are examined in the following paper.  This is something to explore further.\n",
      "</br>\n",
      "Austin, P. C. (2014), A comparison of 12 algorithms for matching on the propensity score. Statist. Med., 33: 1057\u20131069. doi: 10.1002/sim.6004"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computePropensityScore(predictors, groups):\n",
      "    '''\n",
      "    Compute propensity scores \n",
      "    \n",
      "    Inputs:\n",
      "    predictors = DataFrame containing covariates\n",
      "    groups = Series containing treatment assignment. Indices should match those of predictors.\n",
      "        Must be 2 groups\n",
      "\n",
      "    \n",
      "    dependencies: LogisticRegression from sklearn.linear_model\n",
      "                  statsmodels as sm\n",
      "    '''\n",
      "    \n",
      "    if len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "        \n",
      "    ####### Using LlogisticRegression from sklearn.linear_model    \n",
      "    #propensity = LogisticRegression()\n",
      "    #propensity.fit(predictors, groups)\n",
      "    #return propensity.predict_proba(predictors)[:,1]\n",
      "    \n",
      "    ####### Using sm.GLM\n",
      "    predictors = sm.add_constant(predictors, prepend=False)\n",
      "    glm_binom = sm.GLM(groups, predictors, family=sm.families.Binomial())\n",
      "    res = glm_binom.fit()\n",
      "    return res.fittedvalues"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Match(groups, propensity, caliper = 0.05, caliper_method = \"propensity\", replace = False):\n",
      "    ''' \n",
      "    Implements greedy one-to-one matching on propensity scores.\n",
      "    \n",
      "    Inputs:\n",
      "    groups = Array-like object of treatment assignments.  Must be 2 groups\n",
      "    propensity = Array-like object containing propensity scores for each observation. Propensity and groups should be in the same order (matching indices)\n",
      "    caliper = a numeric value, specifies maximum distance (difference in propensity scores or SD of logit propensity) \n",
      "    caliper_method = a string: \"propensity\" (default) if caliper is a maximum difference in propensity scores,\n",
      "            \"logit\" if caliper is a maximum SD of logit propensity, or \"none\" for no caliper\n",
      "    replace = Logical for whether individuals from the larger group should be allowed to match multiple individuals in the smaller group.\n",
      "        (default is False)\n",
      "    \n",
      "    Output:\n",
      "    A series containing the individuals in the control group matched to the treatment group.\n",
      "    Note that with caliper matching, not every treated individual may have a match.\n",
      "    '''\n",
      "\n",
      "    # Check inputs\n",
      "    if any(propensity <=0) or any(propensity >=1):\n",
      "        raise ValueError('Propensity scores must be between 0 and 1')\n",
      "    elif not(0<=caliper<1):\n",
      "        if caliper_method == \"propensity\" and caliper>1:\n",
      "            raise ValueError('Caliper for \"propensity\" method must be between 0 and 1')\n",
      "        elif caliper<0:\n",
      "            raise ValueError('Caliper cannot be negative')\n",
      "    elif len(groups)!= len(propensity):\n",
      "        raise ValueError('groups and propensity scores must be same dimension')\n",
      "    elif len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "        \n",
      "    \n",
      "    # Transform the propensity scores and caliper when caliper_method is \"logit\" or \"none\"\n",
      "    if caliper_method == \"logit\":\n",
      "        propensity = log(propensity/(1-propensity))\n",
      "        caliper = caliper*np.std(propensity)\n",
      "    elif caliper_method == \"none\":\n",
      "        caliper = 0\n",
      "    \n",
      "    # Code groups as 0 and 1\n",
      "    groups = groups == groups.unique()[0]\n",
      "    N = len(groups)\n",
      "    N1 = groups.sum(); N2 = N-N1\n",
      "    g1, g2 = propensity[groups == 1], (propensity[groups == 0])\n",
      "    # Check if treatment groups got flipped - the smaller should correspond to N1/g1\n",
      "    if N1 > N2:\n",
      "       N1, N2, g1, g2 = N2, N1, g2, g1 \n",
      "        \n",
      "        \n",
      "    # Randomly permute the smaller group to get order for matching\n",
      "    morder = np.random.permutation(N1)\n",
      "    matches = pd.Series(np.empty(N1))\n",
      "    matches[:] = np.NAN\n",
      "    \n",
      "    for m in morder:\n",
      "        dist = abs(g1[m] - g2)\n",
      "        if (dist.min() <= caliper) or not caliper:\n",
      "            matches[m] = dist.argmin()\n",
      "            if not replace:\n",
      "                g2 = g2.drop(matches[m])\n",
      "    return (matches)\n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def averageTreatmentEffect(groups, response, matches):\n",
      "    '''\n",
      "    This works for one-to-one matching\n",
      "    \n",
      "    Inputs:\n",
      "    groups = Series containing treatment assignment. Must be 2 groups\n",
      "    response = Series containing response measurements. Indices should match those of groups.\n",
      "    matches = matched pairs returned from Match\n",
      "    '''\n",
      "    if len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "    \n",
      "    groups = (groups == groups.unique()[0])            \n",
      "    response1, response0 = response[groups==1], response[groups==0]\n",
      "    response0_matched = response0[matches]\n",
      "    response0_matched.index = arange(len(response1))\n",
      "    return response1.mean() - response0_matched.mean()\n",
      "\n",
      "def bootstrapATE(groups, response, propensity, B = 500, caliper = 0.05, caliper_method = \"propensity\", replace = False):\n",
      "    '''\n",
      "    Computes bootstrap standard error of the average treatment effect\n",
      "    Sample observations with replacement, within each treatment group. Then match them and compute ATE\n",
      "    Repeat B times and take standard deviation\n",
      "    \n",
      "    Inputs:\n",
      "    groups = Series containing treatment assignment. Must be 2 groups\n",
      "    response = Series containing response measurements\n",
      "    propensity = Series containing propensity scores\n",
      "    B = number of bootstrap replicates. Default is 500\n",
      "    caliper, replace = arguments to pass to Match    \n",
      "    '''\n",
      "    if len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "\n",
      "    data = pd.DataFrame({'groups':groups, 'response':response, 'propensity':propensity})\n",
      "    boot_ate = np.empty(B)\n",
      "    for i in range(B):\n",
      "        bootdata = data.copy()\n",
      "        for g in groups.unique():\n",
      "            sample = np.random.choice(data.index[data.groups==g], sum(groups == g), replace = True)\n",
      "            newdata =(data[data.groups==g]).ix[sample]\n",
      "            newdata.index = bootdata.index[bootdata.groups == g]\n",
      "            bootdata[bootdata.groups == g] = newdata\n",
      "        pairs = Match(bootdata.groups, bootdata.propensity, caliper = caliper, replace = replace)\n",
      "        boot_ate[i] = averageTreatmentEffect(bootdata.groups, bootdata.response, pairs)\n",
      "    return boot_ate.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Stratify(groups, response, propensity, nbins = 5, verbosity = 0):\n",
      "    ''' \n",
      "    Implements propensity score stratification on quantiles and computes average treatment effects\n",
      "    \n",
      "    Inputs:\n",
      "    groups = Array-like object of treatment assignments.  Must be 2 groups\n",
      "    response = Array-like object containing response measurements\n",
      "    propensity = Array-like object containing propensity scores for each observation. Propensity and groups should be in the same order (matching indices)\n",
      "    nbins = number of stratification groups of approximately equal size. \n",
      "            Default is to stratify on the propensity score quintiles (5)\n",
      "    verbosity = flag for printing and debugging. \n",
      "        0 for no printed output, 1 for some verbosity, 2 for maximum verbosity\n",
      "\n",
      "    dependencies: ModelMatch.py\n",
      "    \n",
      "    Output:\n",
      "\n",
      "    '''    \n",
      "    \n",
      "    if any(propensity <=0) or any(propensity >=1):\n",
      "        raise ValueError('Propensity scores must be between 0 and 1')\n",
      "    elif len(groups)!= len(propensity):\n",
      "        raise ValueError('groups and propensity scores must be same dimension')\n",
      "    elif len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "    \n",
      "    groups = (groups == groups.unique()[0])\n",
      "    bins = binByQuantiles(propensity, nbins = nbins, verbosity = verbosity)\n",
      "    ate = np.empty(nbins)\n",
      "    for b in arange(nbins):\n",
      "        stratum = (bins == b)\n",
      "        response0 = response[(stratum==1) & (groups==0)]\n",
      "        response1 = response[(stratum==1) & (groups==1)]\n",
      "        ate[b] = response1.mean() - response0.mean()\n",
      "        # For diagnostics, print # of group0 and group1 in each stratum\n",
      "    keep = where(isnan(ate) == False)[0]\n",
      "    pooled_ate = np.average(ate[keep], weights = bins.value_counts().order(ascending=False)[keep])\n",
      "    return ate, pooled_ate\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Goal:</b> find the average treatment effect in the treatment group (ATT) on RE78.\n",
      "\n",
      "<b>Import the data:</b> controls and treated from Lalonde/Dehejia papers.  Here's what the site says about the data:\n",
      "\n",
      "The variables from left to right are: treatment indicator (1 if treated, 0 if not treated), age, education, Black (1 if black, 0 otherwise), Hispanic (1 if Hispanic, 0 otherwise), married (1 if married, 0 otherwise), nodegree (1 if no degree, 0 otherwise), RE74 (earnings in 1974), RE75 (earnings in 1975), and RE78 (earnings in 1978).\n",
      "\n",
      "http://users.nber.org/%7Erdehejia/nswdata2.html\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = ['Treated', 'Age', 'Education', 'Black', 'Hispanic', 'Married',\n",
      "         'Nodegree', 'RE74', 'RE75', 'RE78']\n",
      "treated = pd.read_table('/Users/Kellie/Documents/ModelMatch/Data/nswre74_treated.txt', sep = '\\s+',\n",
      "                        header = None, names = names)\n",
      "treated['dataset'] = pd.Series(['treated']*len(treated.index))\n",
      "control = pd.read_table('/Users/Kellie/Documents/ModelMatch/Data/nswre74_control.txt', sep='\\s+', \n",
      "                        header = None, names = names)\n",
      "control['dataset'] = pd.Series(['control']*len(control.index))\n",
      "cps = pd.read_table('/Users/Kellie/Documents/ModelMatch/Data/cps_controls.txt', sep='\\s+', \n",
      "                        header = None, names = names)\n",
      "cps['dataset'] = pd.Series(['CPS']*len(cps.index))\n",
      "psid = pd.read_table('/Users/Kellie/Documents/ModelMatch/Data/psid_controls.txt', sep='\\s+', \n",
      "                        header = None, names = names)\n",
      "psid['dataset'] = pd.Series(['PSID']*len(psid.index))\n",
      "data = pd.concat([treated, cps])\n",
      "data.index = range(len(data.index))\n",
      "print data.head()\n",
      "\n",
      "# Verify some characteristics match the Dehejia & Wahba paper, see table 1\n",
      "print mean(treated.Age), mean(control.Age)\n",
      "print mean(treated.Education), mean(control.Education)\n",
      "print mean(treated.Black), mean(control.Black)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   Treated  Age  Education  Black  Hispanic  Married  Nodegree  RE74  RE75  \\\n",
        "0        1   37         11      1         0        1         1     0     0   \n",
        "1        1   22          9      0         1        0         1     0     0   \n",
        "2        1   30         12      1         0        0         0     0     0   \n",
        "3        1   27         11      1         0        0         1     0     0   \n",
        "4        1   33          8      1         0        0         1     0     0   \n",
        "\n",
        "         RE78  dataset  \n",
        "0   9930.0460  treated  \n",
        "1   3595.8940  treated  \n",
        "2  24909.4500  treated  \n",
        "3   7506.1460  treated  \n",
        "4    289.7899  treated  \n",
        "25.8162162162 25.0538461538\n",
        "10.3459459459 10.0884615385\n",
        "0.843243243243 0.826923076923\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Compute propensity scores</b> to start.  Then we need to separate the treated and controls again (preserve original indexing) in order to match them.\n",
      "\n",
      "\n",
      "We need to compute some additional variables that Dehejia and Wahba use in the model for propensity scores.  Refer to the appendix of their paper to see how they decided to include these variables.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['Age2'] = data['Age']**2\n",
      "data['Age3'] = data['Age']**3\n",
      "data['Education2'] = data['Education']**2\n",
      "# I originally assumed unemployment would be 1 if RE74 were 0 and 0 else; this is not the case.\n",
      "# The indicator is actually flipped in table 2, row 1 (the mean there is 1-mean here); doesn't matter for the model\n",
      "data['U74'] = (data['RE74']==0).astype('int')   \n",
      "data['U75'] = (data['RE75']==0).astype('int')\n",
      "data['SchoolRE74'] = data['Education']*data['RE74']\n",
      "\n",
      "\n",
      "predictors = [col for col in data.columns if col not in ['Treated', 'RE78', 'dataset']]\n",
      "data['Propensity'] = computePropensityScore(data[predictors], data.Treated)\n",
      "\n",
      "pairs = Match(data.Treated, data.Propensity, caliper = 0, caliper_method = \"none\", replace = False)\n",
      "g1, g2 = data.Propensity[data.Treated==1], data.Propensity[data.Treated==0]\n",
      "print \"Unmatched treated individuals: \" + str(pairs.isnull().sum())\n",
      "pairs[:5] # The first 5 matched pairs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unmatched treated individuals: 0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "0    6638\n",
        "1    2546\n",
        "2    1843\n",
        "3    3453\n",
        "4    4204\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Here's the result:</b> if we put the propensity scores of the treatment and matched controls side-by-side, we see that they're matched pretty well.\n",
      "<br>\n",
      "The first row in table 2 of Dehejia & Wahba corresponds to the treatment group here.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print zip(g1, g2[pairs])[:5]\n",
      "print \"Mean propensity score for treatment group:\" + str(mean(g1))\n",
      "print \"Mean propensity score for control group:\" + str(mean(g2))\n",
      "print \"Mean propensity score for matched controls:\" + str(mean(g2[pairs]))\n",
      "\n",
      "print \"Estimated average treatment effect:\" + str(averageTreatmentEffect(groups = data.Treated, response = data.RE78, matches = pairs))\n",
      "#bootstrapATE(groups = data.Treated, response = data.RE78, propensity = data.Propensity, B = 500, caliper = 0, replace = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0.37925655520887563, 0.37178968171408672), (0.42650801180558451, 0.43136416889528423), (0.68254320829152959, 0.68254320829152959), (0.89351988932554793, 0.38688416803700243), (0.89928241773805118, 0.35238913390170029)]\n",
        "Mean propensity score for treatment group:0.422163882458\n",
        "Mean propensity score for control group:0.00668457239552\n",
        "Mean propensity score for matched controls:0.29935190559\n",
        "Estimated average treatment effect:754.063294108\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "724.45619077811466"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Stratify(data.Treated, data.RE78, data.Propensity, nbins = 5, verbosity = 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Quantiles used for binning:\n",
        "[  3.95472347e-10   8.18980863e-06   4.12546092e-05   2.27516327e-04\n",
        "   1.63752473e-03   9.33048292e-01]\n",
        "\n",
        "Number of observations assigned to each bin:\n",
        "1    3231\n",
        "3    3235\n",
        "2    3235\n",
        "4    3236\n",
        "0    3240\n",
        "dtype: int64\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "(array([           nan,            nan,            nan, -3394.77222106,\n",
        "       -1537.78445221]),\n",
        " -2466.1348512586023)"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}