{
 "metadata": {
  "name": "PSM.ipynb",
  "signature": "sha256:daf845121b68fedc6c20fe71f5f45290441e727ef67b53809f4a1ba57a794f9d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Last edited 4 August, 2014 by KO\n",
      "</br>\n",
      "Implements propensity-score matching and eventually will implement balance diagnostics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import math\n",
      "import numpy as np\n",
      "import scipy\n",
      "from scipy.stats import binom, hypergeom\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from ModelMatch import binByQuantiles\n",
      "import statsmodels.api as sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implement one-to-one matching, caliper without replacement.  Variants of the method are examined in the following paper.  This is something to explore further.\n",
      "</br>\n",
      "Austin, P. C. (2014), A comparison of 12 algorithms for matching on the propensity score. Statist. Med., 33: 1057\u20131069. doi: 10.1002/sim.6004"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computePropensityScore(predictors, groups):\n",
      "    '''\n",
      "    Compute propensity scores \n",
      "    \n",
      "    Inputs:\n",
      "    predictors = DataFrame containing covariates\n",
      "    groups = Series containing treatment assignment. Indices should match those of predictors.\n",
      "        Must be 2 groups\n",
      "\n",
      "    \n",
      "    dependencies: LogisticRegression from sklearn.linear_model\n",
      "                  statsmodels as sm\n",
      "    '''\n",
      "    \n",
      "    if len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "        \n",
      "    ####### Using LogisticRegression from sklearn.linear_model    \n",
      "    #propensity = LogisticRegression()\n",
      "    #propensity.fit(predictors, groups)\n",
      "    #return propensity.predict_proba(predictors)[:,1]\n",
      "    \n",
      "    ####### Using sm.GLM\n",
      "    predictors = sm.add_constant(predictors, prepend=False)\n",
      "    glm_binom = sm.GLM(groups, predictors, family=sm.families.Binomial())\n",
      "    res = glm_binom.fit()\n",
      "    return res.fittedvalues"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Match(groups, propensity, caliper = 0.05, caliper_method = \"propensity\", replace = False):\n",
      "    ''' \n",
      "    Implements greedy one-to-one matching on propensity scores.\n",
      "    \n",
      "    Inputs:\n",
      "    groups = Array-like object of treatment assignments.  Must be 2 groups\n",
      "    propensity = Array-like object containing propensity scores for each observation. Propensity and groups should be in the same order (matching indices)\n",
      "    caliper = a numeric value, specifies maximum distance (difference in propensity scores or SD of logit propensity) \n",
      "    caliper_method = a string: \"propensity\" (default) if caliper is a maximum difference in propensity scores,\n",
      "            \"logit\" if caliper is a maximum SD of logit propensity, or \"none\" for no caliper\n",
      "    replace = Logical for whether individuals from the larger group should be allowed to match multiple individuals in the smaller group.\n",
      "        (default is False)\n",
      "    \n",
      "    Output:\n",
      "    A series containing the individuals in the control group matched to the treatment group.\n",
      "    Note that with caliper matching, not every treated individual may have a match.\n",
      "    '''\n",
      "\n",
      "    # Check inputs\n",
      "    if any(propensity <=0) or any(propensity >=1):\n",
      "        raise ValueError('Propensity scores must be between 0 and 1')\n",
      "    elif not(0<=caliper<1):\n",
      "        if caliper_method == \"propensity\" and caliper>1:\n",
      "            raise ValueError('Caliper for \"propensity\" method must be between 0 and 1')\n",
      "        elif caliper<0:\n",
      "            raise ValueError('Caliper cannot be negative')\n",
      "    elif len(groups)!= len(propensity):\n",
      "        raise ValueError('groups and propensity scores must be same dimension')\n",
      "    elif len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "        \n",
      "    \n",
      "    # Transform the propensity scores and caliper when caliper_method is \"logit\" or \"none\"\n",
      "    if caliper_method == \"logit\":\n",
      "        propensity = log(propensity/(1-propensity))\n",
      "        caliper = caliper*np.std(propensity)\n",
      "    elif caliper_method == \"none\":\n",
      "        caliper = 0\n",
      "    \n",
      "    # Code groups as 0 and 1\n",
      "    groups = groups == groups.unique()[0]\n",
      "    N = len(groups)\n",
      "    N1 = groups.sum(); N2 = N-N1\n",
      "    g1, g2 = propensity[groups == 1], propensity[groups == 0]\n",
      "    # Check if treatment groups got flipped - the smaller should correspond to N1/g1\n",
      "    if N1 > N2:\n",
      "       N1, N2, g1, g2 = N2, N1, g2, g1\n",
      "        \n",
      "        \n",
      "    # Randomly permute the smaller group to get order for matching\n",
      "    morder = np.random.permutation(N1)\n",
      "    matches = pd.Series(np.empty(N1))\n",
      "    matches.index = g1.index\n",
      "    matches[:] = np.NAN\n",
      "    \n",
      "    for m in morder:\n",
      "        dist = abs(g1[m] - g2)\n",
      "        if (dist.min() <= caliper) or not caliper:\n",
      "            matches[m] = dist.argmin()    # Potential problem: check for ties\n",
      "            if not replace:\n",
      "                g2 = g2.drop(matches[m])\n",
      "    return (matches)\n",
      "\n",
      "           \n",
      "    #response1, response0 = response[groups==1], response[groups==0]\n",
      "    #response1_matched = response1[matches.notnull()]\n",
      "    #response0_matched = response0[matches]\n",
      "    #response0_matched = response0_matched[response0_matched.notnull()]\n",
      "    \n",
      "    \n",
      "def whichMatched(matches, data):\n",
      "    ''' \n",
      "    Simple function to convert output of Matches to DataFrame of all matched observations\n",
      "    Inputs:\n",
      "    matches = output of Match\n",
      "    data = DataFrame of covariates\n",
      "    '''\n",
      "    keep = matches.notnull()\n",
      "    tr = matches.index[keep]\n",
      "    ctrl = matches[keep]\n",
      "    return pd.concat([data.ix[tr], data.ix[ctrl]])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#def averageTreatmentEffect(groups, response, matches):\n",
      "#    '''\n",
      "#    This works for one-to-one matching\n",
      "#    \n",
      "#    Inputs:\n",
      "#    groups = Series containing treatment assignment. Must be 2 groups\n",
      "#    response = Series containing response measurements. Indices should match those of groups.\n",
      "#    matches = matched pairs returned from Match\n",
      "#    '''\n",
      "#    if len(groups.unique()) != 2:\n",
      "#        raise ValueError('wrong number of groups: expected 2')\n",
      "#    \n",
      "#    groups = (groups == groups.unique()[0])            \n",
      "#    response1, response0 = response[groups==1], response[groups==0]\n",
      "#    response1_matched = response1[matches.notnull()]\n",
      "#    response0_matched = response0[matches]\n",
      "#    response0_matched = response0_matched[response0_matched.notnull()]\n",
      "#    return response1.mean() - response0_matched.mean()\n",
      "\n",
      "def averageTreatmentEffect(groups, response):\n",
      "    '''\n",
      "    This works for one-to-one matching.  The data passed in should already have unmatched individuals removed.\n",
      "    Weights argument will be added later for one-many matching\n",
      "    \n",
      "    Inputs:\n",
      "    groups = Series containing treatment assignment. Must be 2 groups\n",
      "    response = Series containing response measurements. Indices should match those of groups.\n",
      "    '''\n",
      "    if len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "    \n",
      "    groups = (groups == groups.unique()[0])            \n",
      "    response1, response0 = response[groups==1], response[groups==0]\n",
      "    return response1.mean() - response0.mean()\n",
      "\n",
      "\n",
      "def bootstrapATE(groups, response, propensity, B = 500, caliper = 0.05, caliper_method = \"propensity\", replace = False):\n",
      "    '''\n",
      "    Computes bootstrap standard error of the average treatment effect\n",
      "    Sample observations with replacement, within each treatment group. Then match them and compute ATE\n",
      "    Repeat B times and take standard deviation\n",
      "    \n",
      "    Inputs:\n",
      "    groups = Series containing treatment assignment. Must be 2 groups\n",
      "    response = Series containing response measurements\n",
      "    propensity = Series containing propensity scores\n",
      "    B = number of bootstrap replicates. Default is 500\n",
      "    caliper, replace = arguments to pass to Match    \n",
      "    '''\n",
      "    if len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "\n",
      "    data = pd.DataFrame({'groups':groups, 'response':response, 'propensity':propensity})\n",
      "    boot_ate = np.empty(B)\n",
      "    for i in range(B):\n",
      "        bootdata = data.copy()\n",
      "        for g in groups.unique():\n",
      "            sample = np.random.choice(data.index[data.groups==g], sum(groups == g), replace = True)\n",
      "            newdata =(data[data.groups==g]).ix[sample]\n",
      "            newdata.index = bootdata.index[bootdata.groups == g]\n",
      "            bootdata[bootdata.groups == g] = newdata\n",
      "        pairs = Match(bootdata.groups, bootdata.propensity, caliper = caliper, replace = replace)\n",
      "        boot_ate[i] = averageTreatmentEffect(bootdata.groups, bootdata.response)\n",
      "    return boot_ate.std()\n",
      "\n",
      "\n",
      "def regressAverageTreatmentEffect(groups, response, covariates):\n",
      "    '''\n",
      "    This works for one-to-one matching.   The data passed in should already have unmatched individuals removed.\n",
      "    Weights argument will be added later for one-many matching\n",
      "    \n",
      "    Inputs:\n",
      "    groups = Series containing treatment assignment. Must be 2 groups\n",
      "    response = Series containing response measurements. Indices should match those of groups.\n",
      "    covariates = DataFrame containing the covariates to include in the linear regression\n",
      "    \n",
      "    Dependencies: statsmodels.api as sm, pandas as pd\n",
      "    '''\n",
      "    if len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "    \n",
      "    X = pd.concat([groups, covariates], axis=1)\n",
      "    X = sm.add_constant(X, prepend=False)\n",
      "    linmodel = sm.WLS(response, X, weights = 1).fit()\n",
      "    return linmodel.params[0], linmodel.bse[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Stratify(groups, response, propensity, nbins = 5, verbosity = 0):\n",
      "    ''' \n",
      "    Implements propensity score stratification on quantiles and computes average treatment effects\n",
      "    \n",
      "    Inputs:\n",
      "    groups = Array-like object of treatment assignments.  Must be 2 groups\n",
      "    response = Array-like object containing response measurements\n",
      "    propensity = Array-like object containing propensity scores for each observation. Propensity and groups should be in the same order (matching indices)\n",
      "    nbins = number of stratification groups of approximately equal size. \n",
      "            Default is to stratify on the propensity score quintiles (5)\n",
      "    verbosity = flag for printing and debugging. \n",
      "        0 for no printed output, 1 for some verbosity, 2 for maximum verbosity\n",
      "\n",
      "    dependencies: ModelMatch.py\n",
      "    \n",
      "    Output:\n",
      "\n",
      "    '''    \n",
      "    \n",
      "    if any(propensity <=0) or any(propensity >=1):\n",
      "        raise ValueError('Propensity scores must be between 0 and 1')\n",
      "    elif len(groups)!= len(propensity):\n",
      "        raise ValueError('groups and propensity scores must be same dimension')\n",
      "    elif len(groups.unique()) != 2:\n",
      "        raise ValueError('wrong number of groups: expected 2')\n",
      "    \n",
      "    groups = (groups == groups.unique()[0])\n",
      "    bins = binByQuantiles(propensity, nbins = nbins, verbosity = verbosity)\n",
      "    ate = np.empty(nbins)\n",
      "    for b in arange(nbins):\n",
      "        stratum = (bins == b)\n",
      "        response0 = response[(stratum==1) & (groups==0)]\n",
      "        response1 = response[(stratum==1) & (groups==1)]\n",
      "        ate[b] = response1.mean() - response0.mean()\n",
      "        # For diagnostics, print # of group0 and group1 in each stratum\n",
      "    keep = where(isnan(ate) == False)[0]\n",
      "    pooled_ate = np.average(ate[keep], weights = bins.value_counts().order(ascending=False)[keep])\n",
      "    return ate, pooled_ate\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}